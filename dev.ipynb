{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as pt\n",
    "import re\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class KnnCpgFeatureExtractor(object):\n",
    "    \"\"\"Extracts k CpG sites next to target sites. Excludes CpG sites at the\n",
    "    same position.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k=1):\n",
    "        self.k = k\n",
    "\n",
    "        t = [''] * 4 * k\n",
    "        for i in range(k):\n",
    "            t[k - 1 - i] = 'cpg_l_%d' % (i + 1)\n",
    "            t[k + i] = 'cpg_r_%d' % (i + 1)\n",
    "            t[3 * k - 1 - i] = 'dist_l_%d' % (i + 1)\n",
    "            t[3 * k + i] = 'dist_r_%d' % (i + 1)\n",
    "        self.labels = t\n",
    "\n",
    "    def extract(self, x, y, ys):\n",
    "        \"\"\"Extracts state and distance of k CpG sites next to target sites.\n",
    "        Target site is excluded.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: numpy array with target positions sorted in ascending order\n",
    "        y: numpy array with source positions sorted in ascending order\n",
    "        ys: numpy array with source CpG states\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy array with len(x) rows and 4*k columns:\n",
    "            0:k     CpG states left side\n",
    "            k:2k    CpG states right side\n",
    "            2k:3k   Distances left side\n",
    "            3k:4k   Distances right side\n",
    "        \"\"\"\n",
    "\n",
    "        n = len(x)\n",
    "        m = len(y)\n",
    "        k = self.k\n",
    "        kk = 2 * self.k\n",
    "        yc = self.__larger_equal(x, y)\n",
    "        rv = np.empty((n, 4 * k))\n",
    "        rv.fill(np.nan)\n",
    "        for i in range(n):\n",
    "            # Left side\n",
    "            yl = yc[i] - k\n",
    "            yr = yc[i] - 1\n",
    "            if yr >= 0:\n",
    "                xl = 0\n",
    "                xr = k - 1\n",
    "                if yl < 0:\n",
    "                    xl += np.abs(yl)\n",
    "                    yl = 0\n",
    "                xr += 1\n",
    "                yr += 1\n",
    "                # CpG states\n",
    "                rv[i, xl:xr] = ys[yl:yr]\n",
    "                xl += kk\n",
    "                xr += kk\n",
    "                # Distance\n",
    "                rv[i, xl:xr] = np.abs(y[yl:yr] - x[i])\n",
    "\n",
    "            # Right side\n",
    "            yl = yc[i]\n",
    "            if yl >= m:\n",
    "                continue\n",
    "            if x[i] == y[yl]:\n",
    "                yl += 1\n",
    "                if yl >= m:\n",
    "                    continue\n",
    "            yr = yl + k - 1\n",
    "            xl = 0\n",
    "            xr = k - 1\n",
    "            if yr >= m:\n",
    "                xr -= yr - m + 1\n",
    "                yr = m - 1\n",
    "            xl += k\n",
    "            xr += k + 1\n",
    "            yr += 1\n",
    "            # CpG state\n",
    "            rv[i, xl:xr] = ys[yl:yr]\n",
    "            xl += kk\n",
    "            xr += kk\n",
    "            # Distance\n",
    "            rv[i, xl:xr] = np.abs(y[yl:yr] - x[i])\n",
    "        return rv\n",
    "\n",
    "    def __larger_equal(self, x, y):\n",
    "        \"\"\"Returns for each x[i] index j, s.t. y[j] >= x[i].\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : numpy array of with positions sorted in ascending order\n",
    "        y : numpy array of with positions sorted in ascending order\n",
    "        \"\"\"\n",
    "\n",
    "        n = len(x)\n",
    "        m = len(y)\n",
    "        rv = np.empty(n, dtype=np.int)\n",
    "        i = 0\n",
    "        j = 0\n",
    "        while i < n and j < m:\n",
    "            while j < m and x[i] > y[j]:\n",
    "                j += 1\n",
    "            rv[i] = j\n",
    "            i += 1\n",
    "        if i < n:\n",
    "            # x[i] > y[m - 1]\n",
    "            rv[i:] = m\n",
    "        return rv\n",
    "    \n",
    "    \n",
    "class IntervalFeatureExtractor(object):\n",
    "    \"\"\"Checks if positions are in a list of intervals (start, end).\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def join_intervals(s, e):\n",
    "        \"\"\"Transforms a list of possible overlapping intervals into\n",
    "        non-overlapping intervals.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        s : list with start of interval sorted in ascending order\n",
    "        e : list with end of interval\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple (s, e) of non-overlapping intervals\n",
    "        \"\"\"\n",
    "\n",
    "        rs = []\n",
    "        re = []\n",
    "        n = len(s)\n",
    "        if n == 0:\n",
    "            return (rs, re)\n",
    "        l = s[0]\n",
    "        r = e[0]\n",
    "        for i in range(1, n):\n",
    "            if s[i] > r:\n",
    "                rs.append(l)\n",
    "                re.append(r)\n",
    "                l = s[i]\n",
    "                r = e[i]\n",
    "            else:\n",
    "                r = max(r, e[i])\n",
    "        rs.append(l)\n",
    "        re.append(r)\n",
    "        return (rs, re)\n",
    "\n",
    "    @staticmethod\n",
    "    def index_intervals(x, ys, ye):\n",
    "        \"\"\"Returns for positions x[i] index j, s.t. ys[j] <= x[i] <= ye[j] or -1.\n",
    "           Intervals must be non-overlapping!\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : list of positions\n",
    "        ys: list with start of interval sorted in ascending order\n",
    "        ye: list with end of interval\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy array of same length than x with index or -1\n",
    "        \"\"\"\n",
    "\n",
    "        n = len(ys)\n",
    "        m = len(x)\n",
    "        rv = np.empty(m, dtype=np.int)\n",
    "        rv.fill(-1)\n",
    "        i = 0\n",
    "        j = 0\n",
    "        while i < n and j < m:\n",
    "            while j < m and x[j] <= ye[i]:\n",
    "                if x[j] >= ys[i]:\n",
    "                    rv[j] = i\n",
    "                j += 1\n",
    "            i += 1\n",
    "        return rv\n",
    "\n",
    "    def extract(self, x, ys, ye):\n",
    "        return self.index_intervals(x, ys, ye) >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def format_chromo(chromo):\n",
    "    chromo = str(chromo)\n",
    "    chromo = chromo.upper()\n",
    "    chromo = re.sub('^CHR', '', chromo)\n",
    "    return chromo\n",
    "\n",
    "def format_chromos(chromos):\n",
    "    return [format_chromo(x) for x in chromos]\n",
    "\n",
    "def read_txt(filename, nrows=None):\n",
    "    d = pd.read_table(filename)\n",
    "    sample = d.columns[-1]\n",
    "    d = d.iloc[:, [0, 1, 3]]\n",
    "    d.columns = ['chromo', 'pos', 'value']\n",
    "    d['sample'] = sample\n",
    "    d['chromo'] = format_chromos(d['chromo'])\n",
    "    return d\n",
    "\n",
    "def read_txts(filenames):\n",
    "    return pd.concat([read_txt(f) for f in filenames])\n",
    "\n",
    "def read_bed(filename):\n",
    "    d = pd.read_table(filename, header=None)\n",
    "    d = d.iloc[:, :3]\n",
    "    d.columns = ['chromo', 'start', 'end']\n",
    "    d['chromo'] = format_chromos(d['chromo'])\n",
    "    return d\n",
    "\n",
    "def read_annos(filenames):\n",
    "    anno_tables = {}\n",
    "    for anno_file in filenames:\n",
    "        anno_table = read_bed(anno_file)\n",
    "        anno_table = anno_table.sort(['chromo', 'start'])\n",
    "        anno_name = pt.splitext(pt.basename(anno_file))[0]\n",
    "        anno_tables[anno_name] = anno_table\n",
    "    return anno_tables\n",
    "\n",
    "def spread(d):\n",
    "    return pd.pivot_table(d, index=['chromo', 'pos'], columns='sample', values='value')\n",
    "\n",
    "def gather(d):\n",
    "    return pd.melt(d.reset_index(), id_vars=['chromo', 'pos'], var_name='sample', value_name='value')\n",
    "\n",
    "def is_int(d):\n",
    "    return d == round(d)\n",
    "\n",
    "def size_to_int(size, n):\n",
    "    if is_int(size):\n",
    "        return size\n",
    "    else:\n",
    "        return round(size * n)\n",
    "    \n",
    "def train_test(d, test_size=0.5):\n",
    "    n = d.shape[0]\n",
    "    test_size = size_to_int(test_size, n)\n",
    "    idx = np.arange(n)\n",
    "    test_idx = np.random.choice(idx, test_size, replace=False)\n",
    "    test_idx = np.in1d(idx, test_idx)\n",
    "    train = d.loc[~test_idx]\n",
    "    test = d.loc[test_idx]\n",
    "    return (train, test)\n",
    "\n",
    "def train_test_eval(d, test_size=0.5, eval_size=0.1):\n",
    "    h, test = train_test(d, test_size)\n",
    "    train, eval_ = train_test(h, eval_size)\n",
    "    return (train, test, eval_)\n",
    "\n",
    "def group_apply(d, by, fun, *args, **kwargs):\n",
    "    g = d.groupby(by)\n",
    "    r_all = []\n",
    "    for k in g.groups.keys():\n",
    "        dg = g.get_group(k)\n",
    "        r = fun(dg, *args, **kwargs)\n",
    "        if type(by) is list:\n",
    "            for i in range(len(by)):\n",
    "                r[by[i]] = k[i]\n",
    "        else:\n",
    "            r[by] = k\n",
    "        r_all.append(r)\n",
    "    r_all = pd.concat(r_all)\n",
    "    return r_all\n",
    "\n",
    "def get_pos(d):\n",
    "    return pd.pivot_table(d, index=['chromo', 'pos'], columns='sample', values='value').reset_index()['pos'].values\n",
    "    \n",
    "\n",
    "def knn_features_sample(d, fe, pos):\n",
    "    f = fe.extract(pos, d['pos'].values, d['value'].values)\n",
    "    f = pd.DataFrame(f, columns=fe.labels)\n",
    "    f['pos'] = pos\n",
    "    f = pd.melt(f, id_vars='pos', var_name='feature', value_name='value')\n",
    "    return f\n",
    "        \n",
    "def knn_features_chromo(d, fe):\n",
    "    pos = get_pos(d)\n",
    "    return group_apply(d, 'sample', knn_features_sample, fe, pos)\n",
    "           \n",
    "def knn_features(d, k=5):\n",
    "    fe = KnnCpgFeatureExtractor(k)\n",
    "    return group_apply(d, 'chromo', knn_features_chromo, fe)\n",
    "\n",
    "def anno_features_chromo(d, annos, fe):\n",
    "    pos = get_pos(d)\n",
    "    f_all = []\n",
    "    for anno_name, anno_table in annos.items():\n",
    "        start, end = fe.join_intervals(anno_table['start'].values, anno_table['end'].values)\n",
    "        f = fe.extract(pos, start, end)\n",
    "        f = pd.DataFrame(dict(pos=pos, feature=anno_name, value=f))\n",
    "        f_all.append(f)\n",
    "    f_all = pd.concat(f_all)\n",
    "    return f_all\n",
    "\n",
    "def anno_features(d, annos):\n",
    "    fe = IntervalFeatureExtractor()\n",
    "    return group_apply(d, 'chromo', anno_features_chromo, annos, fe)\n",
    "\n",
    "def features(d, k=5, annos=None):\n",
    "    f_all = []\n",
    "    f = d.copy()\n",
    "    f['feature'] = 'cpg'\n",
    "    f_all.append(f)\n",
    "    if k is not None:\n",
    "        f = knn_features(d, k)\n",
    "        f['feature'] = ['knn_' + x for x in f['feature']]\n",
    "        f_all.append(f)\n",
    "        \n",
    "    if annos is not None:\n",
    "        f = anno_features(d, annos)\n",
    "        f['sample'] = 'global'\n",
    "        f['feature'] = ['anno_' + x for x in f['feature']]\n",
    "        f_all.append(f)\n",
    "    f_all = pd.concat(f_all)\n",
    "    return f_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = '''chromo pos s1 s2\n",
    "1 1 1 NA\n",
    "1 2 NA 0\n",
    "1 3 1 0\n",
    "2 1 0 0\n",
    "2 3 1 0\n",
    "'''\n",
    "dcpg = pd.read_table(StringIO(s), sep=' ')\n",
    "dt = dict()\n",
    "dt['cpg'] = pd.melt(dcpg, id_vars=['chromo', 'pos'], var_name='sample', value_name='value').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = dict()\n",
    "d['cpg'] = read_txts(['txt/CSC2_3B.txt', 'txt/CSC2_3C.txt', 'txt/CSC4_7B.txt'])\n",
    "d['annos'] = read_annos(['annos/gene_body.bed', 'annos/LMRs.bed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dc = train_test_eval(d['cpg'])\n",
    "df = [features(x, k=5, annos=d['annos']) for x in dc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chromo</th>\n",
       "      <th>feature</th>\n",
       "      <th>pos</th>\n",
       "      <th>sample</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>cpg</td>\n",
       "      <td>3003339</td>\n",
       "      <td>CSC2_3B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>cpg</td>\n",
       "      <td>3014601</td>\n",
       "      <td>CSC2_3B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>cpg</td>\n",
       "      <td>3017624</td>\n",
       "      <td>CSC2_3B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>cpg</td>\n",
       "      <td>3019021</td>\n",
       "      <td>CSC2_3B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>cpg</td>\n",
       "      <td>3020724</td>\n",
       "      <td>CSC2_3B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chromo feature      pos   sample  value\n",
       "0      1     cpg  3003339  CSC2_3B      1\n",
       "3      1     cpg  3014601  CSC2_3B      1\n",
       "4      1     cpg  3017624  CSC2_3B      1\n",
       "5      1     cpg  3019021  CSC2_3B      1\n",
       "7      1     cpg  3020724  CSC2_3B      1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[0].to_hdf('data.h5', 'train')\n",
    "df[1].to_hdf('data.h5', 'test')\n",
    "df[2].to_hdf('data.h5', 'eval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import sklearn.metrics as met\n",
    "import sklearn.base as skb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_table(d, exclude=['knn_dist']):\n",
    "    if exclude is not None:\n",
    "        h = d.feature.str.startswith(exclude[0])\n",
    "        for e in exclude[1:]:\n",
    "            h |= d.feature.str.startswith(e)    \n",
    "        d = d.loc[~h]\n",
    "    d = pd.pivot_table(d, index=['chromo', 'pos'], columns=['sample', 'feature'], values='value')\n",
    "    return d\n",
    "\n",
    "def split_Xy(d, sample):\n",
    "    h = ~d[(sample, 'cpg')].isnull()\n",
    "    d = d.loc[h]\n",
    "    d = d[[x for x in d.columns if x[0] == sample or not x[1].startswith('cpg')]]\n",
    "    d = d.dropna()\n",
    "    y = d[(sample, 'cpg')]\n",
    "    x = d[[x for x in d.columns if x != (sample, 'cpg')]]\n",
    "    return (x, y)\n",
    "\n",
    "def split_XY(d):\n",
    "    is_y = np.array([x[1] == 'cpg' for x in d.columns], dtype='bool')\n",
    "    Y = d.loc[:, is_y]\n",
    "    X = d.loc[:, ~is_y]\n",
    "    h = ~X.isnull().any(axis=1)\n",
    "    X = X.loc[h]\n",
    "    Y = Y.loc[h]\n",
    "    Y.columns = Y.columns.get_level_values(0)\n",
    "    return (X, Y)\n",
    "    \n",
    "class MultitaskClassifier(object):\n",
    "    \n",
    "    def __init__(self, m):\n",
    "        self.model = m\n",
    "        \n",
    "    def Xy_(self, X, Y, task):\n",
    "        y = Y[:, task]\n",
    "        h = ~np.isnan(y)\n",
    "        X = X[h]\n",
    "        y = y[h]\n",
    "        return (X, y)\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        X = np.asarray(X)\n",
    "        Y = np.asarray(Y)\n",
    "        self.num_tasks = Y.shape[1]\n",
    "        self.models = []\n",
    "        for task in range(self.num_tasks):\n",
    "            Xt, yt = self.Xy_(X, Y, task)\n",
    "            m = skb.clone(self.model)\n",
    "            m.fit(Xt, yt)\n",
    "            self.models.append(m)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X)\n",
    "        Y = np.empty((X.shape[0], self.num_tasks))\n",
    "        for task in range(self.num_tasks):\n",
    "            Y[:, task] = self.models[task].predict(X)\n",
    "        return Y\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X = np.asarray(X)\n",
    "        Y = np.empty((X.shape[0], self.num_tasks, 2))\n",
    "        for task in range(self.num_tasks):\n",
    "            Y[:, task] = self.models[task].predict_proba(X)\n",
    "        return Y  \n",
    "    \n",
    "def complete_cases(x, y=None):\n",
    "    x = [x]\n",
    "    if y is not None:\n",
    "        x.append(y)\n",
    "    x = [np.asarray(x_) for x_ in x]\n",
    "    h = None\n",
    "    for x_ in x:\n",
    "        if len(x_.shape) == 1:\n",
    "            hx = ~np.isnan(x_)\n",
    "        else:\n",
    "            hx = ~np.any(np.isnan(x_), axis=1)\n",
    "        if h is None:\n",
    "            h = hx\n",
    "        else:\n",
    "            h &= hx\n",
    "    xc = [x_[h] for x_ in x]\n",
    "    return xc\n",
    "                \n",
    "def score(Y, Yp, fun=met.roc_auc_score):\n",
    "    y = np.asarray(Y).ravel()\n",
    "    yp = np.asarray(Yp).ravel()\n",
    "    y, yp = complete_cases(y, yp)\n",
    "    return fun(y, yp)\n",
    "\n",
    "def scores(Y, Yp, fun=met.roc_auc_score):\n",
    "    Y = np.asarray(Y)\n",
    "    Yp = np.asarray(Yp)\n",
    "    num_tasks = Y.shape[1]\n",
    "    scores = []\n",
    "    for task in range(num_tasks):\n",
    "        y = Y[:, task]\n",
    "        yp = Yp[:, task] \n",
    "        y, yp = complete_cases(y, yp)\n",
    "        scores.append(fun(y, yp))\n",
    "    return scores\n",
    "\n",
    "def to_data_frame(x, y):\n",
    "    assert np.all(x.shape == y.shape)\n",
    "    x = pd.DataFrame(x)\n",
    "    x.index = y.index\n",
    "    x.columns = y.columns\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = [pd.read_hdf('data.h5', x) for x in ['train', 'test']]\n",
    "df = [feature_table(x) for x in df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = MultitaskClassifier(RandomForestClassifier(max_depth=10))\n",
    "X, Y = split_XY(df[0])\n",
    "m.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YY = m.predict_proba(X)[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.91810242102893502, 0.89371233721821164, 0.80348348084557109]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores(Y, YY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89133986842401292"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(Y, YY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y = split_XY(df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YY = m.predict_proba(X)[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.90349002637890696, 0.8802531539363152, 0.77811938320487928]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores(Y, YY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8767470504973518"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(Y, YY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YY = to_data_frame(YY, Y)\n",
    "X.to_hdf('predict.h5', 'X')\n",
    "Y.to_hdf('predict.h5', 'Y')\n",
    "YY.to_hdf('predict.h5', 'YP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rolling_apply(d, delta, fun, *args, **kwargs):\n",
    "    rv = None\n",
    "    for i in range(d.shape[0]):\n",
    "        p = d.index[i]\n",
    "        l = i\n",
    "        while l > 0 and abs(d.index[l - 1] - p) <= delta:\n",
    "            l -= 1\n",
    "        r = i\n",
    "        while r < d.shape[0] - 1 and abs(d.index[r + 1] - p) <= delta:\n",
    "            r += 1\n",
    "        di = d.iloc[l:(r + 1)]\n",
    "        rvi = np.atleast_1d(fun(di, *args, **kwargs))\n",
    "        if rv is None:\n",
    "            rv = np.empty((d.shape[0], rvi.shape[0]))\n",
    "        rv[i] = rvi\n",
    "    rv = pd.DataFrame(rv, index=d.index)\n",
    "    return rv\n",
    "\n",
    "def cpg_cov(x, mean=False):\n",
    "    h = np.mean(~np.isnan(x), axis=1)\n",
    "    if mean:\n",
    "        h = h.mean()\n",
    "    return h\n",
    "\n",
    "def cpg_density(x, c=1):\n",
    "    return x.shape[0] / c\n",
    "\n",
    "def var(x):\n",
    "    x = np.ma.masked_array(x, np.isnan(x))\n",
    "    return x.mean(axis=0).var()\n",
    "\n",
    "def min_dist(x):\n",
    "    \"\"\"x is position vector\"\"\"\n",
    "    rv = np.empty(len(x))\n",
    "    rv.fill(np.nan)\n",
    "    for i in range(len(x)):\n",
    "        h = []\n",
    "        if i > 0:\n",
    "            h.append(abs(x[i] - x[i - 1]))\n",
    "        if i < len(x) - 1:\n",
    "            h.append(abs(x[i] - x[i + 1]))\n",
    "        if len(h) > 0:\n",
    "            rv[i] = min(h)\n",
    "    return rv\n",
    "\n",
    "def min_dist_nn(x, fun=np.mean):\n",
    "    h = []\n",
    "    for i in range(x.shape[1]):\n",
    "        xi = x.iloc[:, i].dropna()\n",
    "        h.append(pd.DataFrame(min_dist(xi.index), index=xi.index))\n",
    "    h = pd.concat(h, axis=1)\n",
    "    h.columns = x.columns\n",
    "    assert np.all(h.shape == x.shape)\n",
    "    if fun is not None:\n",
    "        h = np.ma.masked_array(h, np.isnan(h))\n",
    "        h = fun(h, axis=1).data\n",
    "        h[h == 0] = np.nan\n",
    "    return h\n",
    "\n",
    "def stats(x, delta=1500):\n",
    "    s = []\n",
    "    s.append(cpg_cov(x))\n",
    "    s.append(min_dist_nn(x))\n",
    "    s.append(rolling_apply(x, delta, cpg_cov, mean=True))\n",
    "    s.append(rolling_apply(x, delta, cpg_density, c=(2 * delta + 1)))\n",
    "    s.append(rolling_apply(x, delta, var))\n",
    "    s = [pd.DataFrame(s_, index=x.index) for s_ in s]\n",
    "    s = pd.concat(s, axis=1)\n",
    "    s.columns = ['cpg_cov', 'min_dist', 'win_cpg_cov', 'win_cpg_density', 'win_var']\n",
    "    assert s.shape[0] == x.shape[0]\n",
    "    return s\n",
    "\n",
    "def group_apply(d, by, fun, level=False, *args, **kwargs):\n",
    "    if level:\n",
    "        g = d.groupby(level=by)\n",
    "    else:\n",
    "        g = d.groupby(by)\n",
    "    r_all = []\n",
    "    for k in g.groups.keys():\n",
    "        dg = g.get_group(k)\n",
    "        r = fun(dg, *args, **kwargs)\n",
    "        if type(by) is list:\n",
    "            for i in range(len(by)):\n",
    "                r[by[i]] = k[i]\n",
    "        else:\n",
    "            r[by] = k\n",
    "        r = r.set_index(by, append=True)\n",
    "        r = r.swaplevel(0, r.index.nlevels-1)\n",
    "        r_all.append(r)\n",
    "    r_all = pd.concat(r_all)\n",
    "    return r_all\n",
    "\n",
    "def stats_all(d, *args, **kwargs):\n",
    "    def set_index(d):\n",
    "        d.index = d.index.get_level_values(1)\n",
    "        return d\n",
    "    return group_apply(d, 'chromo', lambda x: stats(set_index(x)), level=True)\n",
    "\n",
    "def export_R(X, Y, Z, S, filename='eval'):\n",
    "    X = X.copy()\n",
    "    X.columns = ['_'.join(x) for x in X.columns.values]\n",
    "    d = dict(X=X, Y=Y, Z=Z, S=S)\n",
    "    for k, v in d.items():\n",
    "        v = v.reset_index()\n",
    "        fn = '%s_%s.csv' % (filename, k)\n",
    "        v.to_csv(fn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_hdf('predict.h5', 'X')\n",
    "Y = pd.read_hdf('predict.h5', 'Y')\n",
    "Z = pd.read_hdf('predict.h5', 'YP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S = stats_all(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export_R(X, Y, Z, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rpy2.robjects import r\n",
    "import pandas.rpy.common as com\n",
    "\n",
    "def join_index(index, sep='_'):\n",
    "    return [sep.join(x) for x in index.values]\n",
    "\n",
    "def to_r(d):\n",
    "    if d.columns.nlevels > 1:\n",
    "        d = d.copy()\n",
    "        d.columns = join_index(d.columns)\n",
    "    d = d.reset_index()\n",
    "    d = com.convert_to_r_dataframe(d)\n",
    "    convert = r(\"\"\"\n",
    "    function(df) {\n",
    "        data.frame(lapply(df, function(X) {\n",
    "            if (\"AsIs\" %in% class(X))\n",
    "                class(X) <- class(X)[-match(\"AsIs\", class(X))]\n",
    "            X\n",
    "        }))\n",
    "    }\n",
    "\"\"\")\n",
    "    d = convert(d)\n",
    "    return d\n",
    "\n",
    "def to_rds(d, filename):\n",
    "    if type(d) is dict:\n",
    "        r('d <- list()')\n",
    "        for k, v in d.items():\n",
    "            r.assign('dd', to_r(v))\n",
    "            r('d$%s <- dd' % (k))\n",
    "    else:\n",
    "        r.assign('d', to_r(d))\n",
    "    r(\"saveRDS(d, '%s')\" % (filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_rds({'X': X.head(), 'Y': Y.head(), 'Z': Z.head(), 'S': X.head()}, 'test.rds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
