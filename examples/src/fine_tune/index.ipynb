{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning a pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial describes how to fine-tune a pre-trained model from the [DeepCpG model zoo](https://github.com/cangermueller/deepcpg/blob/master/docs/models.md). Fine-tuning a model which has been pre-trained on a cells that are similar to the cells of interest allows to considerably decrease training time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first initialize some variables that will be used throughout the tutorial. `test_mode=1` should be used for testing purposes, which speeds up computations by only using a subset of the data. For real applications, `test_mode=0` should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "function run {\n",
    "  local cmd=$@\n",
    "  echo\n",
    "  echo \"#################################\"\n",
    "  echo $cmd\n",
    "  echo \"#################################\"\n",
    "  eval $cmd\n",
    "}\n",
    "\n",
    "test_mode=1 # set this variable to 0 for production\n",
    "data_dir=\"../../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DeepCpG data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create DeepCpG data files using `dcpg_data.py`. Since we will fine-tune a CpG model, we do not extract sequence windows. Otherwise, `--dna_files` and `--dna_wlen` must to be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO (2017-02-05 21:03:37,367): Reading single-cell profiles ...\r\n",
      "INFO (2017-02-05 21:03:37,844): 10000 samples\r\n",
      "INFO (2017-02-05 21:03:37,845): --------------------------------------------------------------------------------\r\n",
      "INFO (2017-02-05 21:03:37,845): Chromosome 1 ...\r\n",
      "INFO (2017-02-05 21:03:37,882): 10000 / 10000 (100.0%) sites matched minimum coverage filter\r\n",
      "INFO (2017-02-05 21:03:37,882): Chunk \t1 / 1\r\n",
      "INFO (2017-02-05 21:03:37,939): Extracting CpG neighbors ...\r\n",
      "INFO (2017-02-05 21:03:39,508): Done!\r\n"
     ]
    }
   ],
   "source": [
    "dcpg_data=\"./data\"\n",
    "cmd=\"dcpg_data.py\n",
    "    --cpg_profiles $data_dir/cpg/*.tsv\n",
    "    --out_dir $dcpg_data\n",
    "    --cpg_wlen 50\n",
    "    \"\n",
    "if [[ $test_mode -eq 1 ]]; then\n",
    "    cmd=\"$cmd\n",
    "        --nb_sample 10000\n",
    "        \"\n",
    "fi\n",
    "eval $cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading a pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dcpg_download.py` downloads a pre-trained model from the DeepCpG model zoo. Available models and their corresponding description can be found on the [model zoo website](https://github.com/cangermueller/deepcpg/blob/master/docs/models.md), or retrieved with `dcpg_download.py --show`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models: https://github.com/cangermueller/deepcpg/blob/master/docs/models.md\r\n",
      "Hou2016_HCC_cpg\r\n",
      "Hou2016_HCC_dna\r\n",
      "Hou2016_HCC_joint\r\n",
      "Hou2016_HepG2_cpg\r\n",
      "Hou2016_HepG2_dna\r\n",
      "Hou2016_HepG2_joint\r\n",
      "Hou2016_mESC_cpg\r\n",
      "Hou2016_mESC_dna\r\n",
      "Hou2016_mESC_joint\r\n",
      "Smallwood2014_2i_cpg\r\n",
      "Smallwood2014_2i_dna\r\n",
      "Smallwood2014_2i_joint\r\n",
      "Smallwood2014_serum_cpg\r\n",
      "Smallwood2014_serum_dna\r\n",
      "Smallwood2014_serum_joint\r\n"
     ]
    }
   ],
   "source": [
    "dcpg_download.py --show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model name consist of three parts, which are separated by '_'. The first part corresponds to the publication, the second to the cell type, and the third to the model type (CpG, DNA, or joint model). Cells from 'Hou2016' were profiled using scRRBS-seq, cells from 'Smallwood2014' using scBS-seq. 'HCC' and 'HepG2' are human cancer cells, all others mouse cells. The cell-type that is most similar to the cell-type of interest should be used. More information  about the available models can be found [here](https://github.com/cangermueller/deepcpg/blob/master/docs/models.md). \n",
    "\n",
    "Since we are dealing with 2i cells and want to train a CpG model, we will use 'Smallwood2014_2i_cpg':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "#################################\r\n",
      "dcpg_download.py Smallwood2014_2i_cpg -o ./models/Smallwood2014_2i_cpg\r\n",
      "#################################\r\n",
      "INFO (2017-02-05 21:03:41,130): Downloading model ...\r\n",
      "INFO (2017-02-05 21:03:41,131): Model URL: http://www.ebi.ac.uk/~angermue/deepcpg/alias/f89b2e8344012d73e95504da06bcf378\r\n",
      "--2017-02-05 21:03:41--  http://www.ebi.ac.uk/~angermue/deepcpg/alias/f89b2e8344012d73e95504da06bcf378\r\n",
      "Resolving www.ebi.ac.uk (www.ebi.ac.uk)... 193.62.193.80\r\n",
      "Connecting to www.ebi.ac.uk (www.ebi.ac.uk)|193.62.193.80|:80... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 31068468 (30M) [text/plain]\r\n",
      "Saving to: ‘./models/Smallwood2014_2i_cpg/model.zip’\r\n",
      "\r\n",
      "\r",
      "          ./models/   0%[                    ]       0  --.-KB/s               \r",
      "         ./models/S   3%[                    ]   1.04M  5.16MB/s               \r",
      "        ./models/Sm   3%[                    ]   1.15M  2.83MB/s               \r",
      "       ./models/Sma   4%[                    ]   1.42M  2.33MB/s               \r",
      "      ./models/Smal   6%[>                   ]   1.85M  2.29MB/s               \r",
      "     ./models/Small   7%[>                   ]   2.36M  2.34MB/s               \r",
      "    ./models/Smallw   9%[>                   ]   2.88M  2.38MB/s               \r",
      "   ./models/Smallwo  11%[=>                  ]   3.42M  2.41MB/s               \r",
      "  ./models/Smallwoo  13%[=>                  ]   3.95M  2.44MB/s               \r",
      " ./models/Smallwood  15%[==>                 ]   4.50M  2.47MB/s               \r",
      "./models/Smallwood2  17%[==>                 ]   5.05M  2.50MB/s               \r",
      "/models/Smallwood20  18%[==>                 ]   5.56M  2.50MB/s               \r",
      "models/Smallwood201  20%[===>                ]   6.12M  2.52MB/s               \r",
      "odels/Smallwood2014  22%[===>                ]   6.65M  2.53MB/s               \r",
      "dels/Smallwood2014_  24%[===>                ]   7.35M  2.60MB/s               \r",
      "els/Smallwood2014_2  27%[====>               ]   8.01M  2.51MB/s    eta 9s     \r",
      "ls/Smallwood2014_2i  31%[=====>              ]   9.32M  2.60MB/s    eta 9s     \r",
      "s/Smallwood2014_2i_  33%[=====>              ]  10.07M  2.73MB/s    eta 9s     \r",
      "/Smallwood2014_2i_c  36%[======>             ]  10.79M  2.94MB/s    eta 9s     \r",
      "Smallwood2014_2i_cp  39%[======>             ]  11.63M  3.05MB/s    eta 9s     \r",
      "mallwood2014_2i_cpg  42%[=======>            ]  12.55M  3.18MB/s    eta 6s     \r",
      "allwood2014_2i_cpg/  45%[========>           ]  13.44M  3.31MB/s    eta 6s     \r",
      "llwood2014_2i_cpg/m  47%[========>           ]  14.18M  3.37MB/s    eta 6s     \r",
      "lwood2014_2i_cpg/mo  50%[=========>          ]  14.92M  3.42MB/s    eta 6s     \r",
      "wood2014_2i_cpg/mod  52%[=========>          ]  15.67M  3.46MB/s    eta 6s     \r",
      "ood2014_2i_cpg/mode  55%[==========>         ]  16.51M  3.58MB/s    eta 4s     \r",
      "od2014_2i_cpg/model  58%[==========>         ]  17.39M  3.68MB/s    eta 4s     \r",
      "d2014_2i_cpg/model.  62%[===========>        ]  18.39M  3.81MB/s    eta 4s     \r",
      "2014_2i_cpg/model.z  65%[============>       ]  19.34M  3.96MB/s    eta 4s     \r",
      "014_2i_cpg/model.zi  68%[============>       ]  20.30M  4.05MB/s    eta 4s     \r",
      "14_2i_cpg/model.zip  71%[=============>      ]  21.31M  4.14MB/s    eta 2s     \r",
      "4_2i_cpg/model.zip   75%[==============>     ]  22.35M  4.29MB/s    eta 2s     \r",
      "_2i_cpg/model.zip    79%[==============>     ]  23.47M  4.41MB/s    eta 2s     \r",
      "2i_cpg/model.zip     83%[===============>    ]  24.64M  4.54MB/s    eta 2s     \r",
      "i_cpg/model.zip      87%[================>   ]  25.81M  4.69MB/s    eta 2s     \r",
      "_cpg/model.zip       91%[=================>  ]  27.02M  4.78MB/s    eta 1s     \r",
      "cpg/model.zip        95%[==================> ]  28.21M  4.87MB/s    eta 1s     \r",
      "pg/model.zip         98%[==================> ]  29.14M  4.93MB/s    eta 1s     \r",
      "./models/Smallwood2 100%[===================>]  29.63M  4.94MB/s    in 7.7s    \r\n",
      "\r\n",
      "2017-02-05 21:03:48 (3.84 MB/s) - ‘./models/Smallwood2014_2i_cpg/model.zip’ saved [31068468/31068468]\r\n",
      "\r\n",
      "Archive:  ./models/Smallwood2014_2i_cpg/model.zip\r\n",
      "  inflating: ./models/Smallwood2014_2i_cpg/model.h5  \r\n",
      "  inflating: ./models/Smallwood2014_2i_cpg/model.json  \r\n",
      "  inflating: ./models/Smallwood2014_2i_cpg/model_weights.h5  \r\n",
      "  inflating: ./models/Smallwood2014_2i_cpg/model_weights_train.h5  \r\n",
      "  inflating: ./models/Smallwood2014_2i_cpg/model_weights_val.h5  \r\n",
      "INFO (2017-02-05 21:03:49,515): Done!\r\n"
     ]
    }
   ],
   "source": [
    "pretrained_model=\"./models/Smallwood2014_2i_cpg\"\n",
    "cmd=\"dcpg_download.py\n",
    "  $(basename $pretrained_model)\n",
    "  -o $pretrained_model\n",
    "  \"\n",
    "run $cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command downloads and stores model files in the output directory, including the weights and JSON file with the model description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.h5               model_weights.h5       model_weights_val.h5\r\n",
      "model.json             model_weights_train.h5\r\n"
     ]
    }
   ],
   "source": [
    "ls $pretrained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model.json` is the model description, and `model_weights_train.h5` and `model_weights_val.h5` the weights that yielded the highest performance on the training and validation set, respectively. `model.h5` combines `model.json` and `model_weights_val.h5`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fine-tune the downloaded model, we use `--cpg_model` followed by the model directory, and `--fine_tune` to only train the output layers.\n",
    "\n",
    "`--cpg_model $pretrained_model` is equivalent to `--cpg_model $pretrained_model/model.json $pretrained_model/model_weights_val.h5`. To fine-tune the weights with the highest performance on the training set, use `model_weights_train.h5` as input.\n",
    "\n",
    "Without `--fine_tune`, `dcpg_train.py` will train all weights, not only the output layers. This is recommended if the cells that were used for the pre-trained model are only distantly related to the cells of interests, e.g. if cell-types do not match. Training all weights will lead to a higher prediction performance, but also increase training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "#################################\r\n",
      "dcpg_train.py ./data/c1_000000-010000.h5 --val_files ./data/c1_000000-010000.h5 --cpg_model ./models/Smallwood2014_2i_cpg --out_dir ./models/cpg --fine_tune --nb_epoch 2 --nb_train_sample 1000 --nb_val_sample 1000\r\n",
      "#################################\r\n",
      "Using TensorFlow backend.\r\n",
      "INFO (2017-02-05 21:04:02,579): Building model ...\r\n",
      "Replicate names:\r\n",
      "BS27_1_SER, BS27_3_SER, BS27_5_SER, BS27_6_SER, BS27_8_SER\r\n",
      "\r\n",
      "INFO (2017-02-05 21:04:02,620): Loading existing CpG model ...\r\n",
      "INFO (2017-02-05 21:04:02,620): Using model files ./models/Smallwood2014_2i_cpg/model.json ./models/Smallwood2014_2i_cpg/model_weights.h5\r\n",
      "INFO (2017-02-05 21:04:03,921): Replicate names differ: Copying weights to new model ...\r\n",
      "____________________________________________________________________________________________________\r\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \r\n",
      "====================================================================================================\r\n",
      "cpg/state (InputLayer)           (None, 5, 50)         0                                            \r\n",
      "____________________________________________________________________________________________________\r\n",
      "cpg/dist (InputLayer)            (None, 5, 50)         0                                            \r\n",
      "____________________________________________________________________________________________________\r\n",
      "cpg/merge_1 (Merge)              (None, 5, 100)        0           cpg/state[0][0]                  \r\n",
      "                                                                   cpg/dist[0][0]                   \r\n",
      "____________________________________________________________________________________________________\r\n",
      "cpg/timedistributed_1 (TimeDistr (None, 5, 256)        25856       cpg/merge_1[0][0]                \r\n",
      "____________________________________________________________________________________________________\r\n",
      "cpg/bidirectional_1 (Bidirection (None, 512)           787968      cpg/timedistributed_1[0][0]      \r\n",
      "____________________________________________________________________________________________________\r\n",
      "cpg/dropout_1 (Dropout)          (None, 512)           0           cpg/bidirectional_1[0][0]        \r\n",
      "____________________________________________________________________________________________________\r\n",
      "cpg/BS27_1_SER (Dense)           (None, 1)             513         cpg/dropout_1[0][0]              \r\n",
      "____________________________________________________________________________________________________\r\n",
      "cpg/BS27_3_SER (Dense)           (None, 1)             513         cpg/dropout_1[0][0]              \r\n",
      "____________________________________________________________________________________________________\r\n",
      "cpg/BS27_5_SER (Dense)           (None, 1)             513         cpg/dropout_1[0][0]              \r\n",
      "____________________________________________________________________________________________________\r\n",
      "cpg/BS27_6_SER (Dense)           (None, 1)             513         cpg/dropout_1[0][0]              \r\n",
      "____________________________________________________________________________________________________\r\n",
      "cpg/BS27_8_SER (Dense)           (None, 1)             513         cpg/dropout_1[0][0]              \r\n",
      "====================================================================================================\r\n",
      "Total params: 816389\r\n",
      "____________________________________________________________________________________________________\r\n",
      "Layer trainability:\r\n",
      "                layer | trainable\r\n",
      "---------------------------------\r\n",
      "cpg/timedistributed_1 |     False\r\n",
      "  cpg/bidirectional_1 |     False\r\n",
      "        cpg/dropout_1 |     False\r\n",
      "\r\n",
      "INFO (2017-02-05 21:04:04,868): Computing output statistics ...\r\n",
      "Output statistics:\r\n",
      "          name | nb_tot | nb_obs | frac_obs | mean |  var\r\n",
      "---------------------------------------------------------\r\n",
      "cpg/BS27_1_SER |   1000 |    351 |     0.35 | 0.90 | 0.09\r\n",
      "cpg/BS27_3_SER |   1000 |    146 |     0.15 | 0.79 | 0.16\r\n",
      "cpg/BS27_5_SER |   1000 |    220 |     0.22 | 0.85 | 0.12\r\n",
      "cpg/BS27_6_SER |   1000 |    336 |     0.34 | 0.67 | 0.22\r\n",
      "cpg/BS27_8_SER |   1000 |    276 |     0.28 | 0.92 | 0.07\r\n",
      "\r\n",
      "Class weights:\r\n",
      "cpg/BS27_1_SER | cpg/BS27_3_SER | cpg/BS27_5_SER | cpg/BS27_6_SER | cpg/BS27_8_SER\r\n",
      "----------------------------------------------------------------------------------\r\n",
      "        0=0.90 |         0=0.79 |         0=0.85 |         0=0.67 |         0=0.92\r\n",
      "        1=0.10 |         1=0.21 |         1=0.15 |         1=0.33 |         1=0.08\r\n",
      "\r\n",
      "INFO (2017-02-05 21:04:05,151): Loading data ...\r\n",
      "INFO (2017-02-05 21:04:05,154): Initializing callbacks ...\r\n",
      "INFO (2017-02-05 21:04:05,154): Training model ...\r\n",
      "\r\n",
      "Training samples: 1000\r\n",
      "Validation samples: 1000\r\n",
      "Epochs: 2\r\n",
      "Learning rate: 0.0001\r\n",
      "====================================================================================================\r\n",
      "Epoch 1/2\r\n",
      "====================================================================================================\r\n",
      "done (%) | time |   loss |    acc | cpg/BS27_6_SER_loss | cpg/BS27_5_SER_loss | cpg/BS27_8_SER_loss | cpg/BS27_3_SER_loss | cpg/BS27_1_SER_loss | cpg/BS27_3_SER_acc | cpg/BS27_1_SER_acc | cpg/BS27_5_SER_acc | cpg/BS27_8_SER_acc | cpg/BS27_6_SER_acc\r\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\n",
      "    12.8 |  0.0 | 0.4260 | 0.2876 |              0.0711 |              0.1185 |              0.0703 |              0.0935 |              0.0511 |             0.6000 |             0.0889 |             0.5227 |             0.0882 |             0.1379\r\n",
      "    25.6 |  0.0 | 0.3779 | 0.3107 |              0.0734 |              0.0923 |              0.0597 |              0.0771 |              0.0522 |             0.6269 |             0.0955 |             0.6143 |             0.0569 |             0.1599\r\n",
      "    38.4 |  0.0 | 0.3637 | 0.3138 |              0.0775 |              0.0894 |              0.0551 |              0.0712 |              0.0471 |             0.5897 |             0.0875 |             0.6559 |             0.0588 |             0.1773\r\n",
      "    51.2 |  0.0 | 0.3494 | 0.3247 |              0.0768 |              0.0810 |              0.0509 |              0.0704 |              0.0472 |             0.5804 |             0.0976 |             0.7062 |             0.0644 |             0.1746\r\n",
      "    64.0 |  0.0 | 0.3473 | 0.3295 |              0.0810 |              0.0802 |              0.0454 |              0.0714 |              0.0467 |             0.6063 |             0.1019 |             0.7018 |             0.0515 |             0.1859\r\n",
      "    76.8 |  0.0 | 0.3472 | 0.3322 |              0.0838 |              0.0806 |              0.0426 |              0.0736 |              0.0444 |             0.6256 |             0.0988 |             0.6932 |             0.0524 |             0.1909\r\n",
      "    89.6 |  0.0 | 0.3368 | 0.3379 |              0.0839 |              0.0773 |              0.0392 |              0.0710 |              0.0434 |             0.6358 |             0.0903 |             0.7114 |             0.0568 |             0.1954\r\n",
      "   100.0 |  0.0 | 0.3433 | 0.3480 |              0.0857 |              0.0785 |              0.0401 |              0.0708 |              0.0464 |             0.6445 |             0.1055 |             0.7130 |             0.0695 |             0.2076\r\n",
      "Epoch 00000: val_loss improved from inf to 0.93112, saving model to ./models/cpg/model_weights_val.h5\r\n",
      "\r\n",
      " split |   loss |    acc | cpg/BS27_5_SER_loss | cpg/BS27_1_SER_loss | cpg/BS27_6_SER_loss | cpg/BS27_8_SER_loss | cpg/BS27_3_SER_loss | cpg/BS27_3_SER_acc | cpg/BS27_8_SER_acc | cpg/BS27_1_SER_acc | cpg/BS27_5_SER_acc | cpg/BS27_6_SER_acc\r\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\n",
      " train | 0.3433 | 0.3480 |              0.0785 |              0.0464 |              0.0857 |              0.0401 |              0.0708 |             0.6445 |             0.0695 |             0.1055 |             0.7130 |             0.2076\r\n",
      "   val | 0.9311 | 0.4075 |              0.1490 |              0.2481 |              0.2355 |              0.1977 |              0.1009 |             0.6632 |             0.0796 |             0.0955 |             0.8457 |             0.3534\r\n",
      "Learning rate: 9.75e-05\r\n",
      "====================================================================================================\r\n",
      "Epoch 2/2\r\n",
      "====================================================================================================\r\n",
      "done (%) | time |   loss |    acc | cpg/BS27_6_SER_loss | cpg/BS27_5_SER_loss | cpg/BS27_8_SER_loss | cpg/BS27_3_SER_loss | cpg/BS27_1_SER_loss | cpg/BS27_3_SER_acc | cpg/BS27_1_SER_acc | cpg/BS27_5_SER_acc | cpg/BS27_8_SER_acc | cpg/BS27_6_SER_acc\r\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\n",
      "    12.8 |  0.1 | 0.3435 | 0.4013 |              0.0910 |              0.0736 |              0.0470 |              0.0811 |              0.0311 |             0.7838 |             0.0750 |             0.6765 |             0.1892 |             0.2821\r\n",
      "    25.6 |  0.1 | 0.3261 | 0.3615 |              0.0917 |              0.0771 |              0.0364 |              0.0656 |              0.0358 |             0.6597 |             0.0970 |             0.7103 |             0.1074 |             0.2331\r\n",
      "    38.4 |  0.1 | 0.3414 | 0.3604 |              0.0948 |              0.0853 |              0.0360 |              0.0674 |              0.0385 |             0.6398 |             0.1053 |             0.7012 |             0.1272 |             0.2286\r\n",
      "    51.2 |  0.1 | 0.3441 | 0.3664 |              0.0859 |              0.0872 |              0.0377 |              0.0680 |              0.0459 |             0.6443 |             0.1225 |             0.7196 |             0.1224 |             0.2232\r\n",
      "    64.0 |  0.1 | 0.3436 | 0.3729 |              0.0885 |              0.0864 |              0.0392 |              0.0629 |              0.0472 |             0.6207 |             0.1370 |             0.7507 |             0.1403 |             0.2157\r\n",
      "    76.8 |  0.1 | 0.3285 | 0.3756 |              0.0837 |              0.0811 |              0.0384 |              0.0590 |              0.0470 |             0.6222 |             0.1367 |             0.7645 |             0.1345 |             0.2200\r\n",
      "    89.6 |  0.1 | 0.3297 | 0.3798 |              0.0877 |              0.0779 |              0.0384 |              0.0583 |              0.0481 |             0.6180 |             0.1426 |             0.7807 |             0.1269 |             0.2308\r\n",
      "   100.0 |  0.1 | 0.3315 | 0.3844 |              0.0879 |              0.0784 |              0.0358 |              0.0610 |              0.0492 |             0.6242 |             0.1563 |             0.7808 |             0.1137 |             0.2470\r\n",
      "Epoch 00001: val_loss improved from 0.93112 to 0.92941, saving model to ./models/cpg/model_weights_val.h5\r\n",
      "\r\n",
      " split |   loss |    acc | cpg/BS27_5_SER_loss | cpg/BS27_1_SER_loss | cpg/BS27_6_SER_loss | cpg/BS27_8_SER_loss | cpg/BS27_3_SER_loss | cpg/BS27_3_SER_acc | cpg/BS27_8_SER_acc | cpg/BS27_1_SER_acc | cpg/BS27_5_SER_acc | cpg/BS27_6_SER_acc\r\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\n",
      " train | 0.3315 | 0.3844 |              0.0784 |              0.0492 |              0.0879 |              0.0358 |              0.0610 |             0.6242 |             0.1137 |             0.1563 |             0.7808 |             0.2470\r\n",
      "   val | 0.9294 | 0.4342 |              0.1509 |              0.2460 |              0.2330 |              0.1984 |              0.1010 |             0.6011 |             0.0796 |             0.1265 |             0.8501 |             0.5139\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "Training set performance:\r\n",
      "  loss |    acc | cpg/BS27_5_SER_loss | cpg/BS27_1_SER_loss | cpg/BS27_6_SER_loss | cpg/BS27_8_SER_loss | cpg/BS27_3_SER_loss | cpg/BS27_3_SER_acc | cpg/BS27_8_SER_acc | cpg/BS27_1_SER_acc | cpg/BS27_5_SER_acc | cpg/BS27_6_SER_acc\r\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\n",
      "0.3433 | 0.3480 |              0.0785 |              0.0464 |              0.0857 |              0.0401 |              0.0708 |             0.6445 |             0.0695 |             0.1055 |             0.7130 |             0.2076\r\n",
      "0.3315 | 0.3844 |              0.0784 |              0.0492 |              0.0879 |              0.0358 |              0.0610 |             0.6242 |             0.1137 |             0.1563 |             0.7808 |             0.2470\r\n",
      "\r\n",
      "Validation set performance:\r\n",
      "  loss |    acc | cpg/BS27_8_SER_loss | cpg/BS27_1_SER_loss | cpg/BS27_3_SER_loss | cpg/BS27_5_SER_loss | cpg/BS27_6_SER_loss | cpg/BS27_8_SER_acc | cpg/BS27_6_SER_acc | cpg/BS27_1_SER_acc | cpg/BS27_3_SER_acc | cpg/BS27_5_SER_acc\r\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\n",
      "0.9311 | 0.4075 |              0.1977 |              0.2481 |              0.1009 |              0.1490 |              0.2355 |             0.0796 |             0.3534 |             0.0955 |             0.6632 |             0.8457\r\n",
      "0.9294 | 0.4342 |              0.1984 |              0.2460 |              0.1010 |              0.1509 |              0.2330 |             0.0796 |             0.5139 |             0.1265 |             0.6011 |             0.8501\r\n",
      "INFO (2017-02-05 21:04:20,411): Done!\r\n"
     ]
    }
   ],
   "source": [
    "cmd=\"dcpg_train.py\n",
    "   ./data/*.h5\n",
    "  --val_files ./data/*.h5\n",
    "  --cpg_model $pretrained_model\n",
    "  --out_dir ./models/cpg\n",
    "  --fine_tune\n",
    "  \"\n",
    "if [[ $test_mode -eq 1 ]]; then\n",
    "  cmd=\"$cmd\n",
    "    --nb_epoch 2\n",
    "    --nb_train_sample 1000\n",
    "    --nb_val_sample 1000\n",
    "    \"\n",
    "else\n",
    "  cmd=\"$cmd\n",
    "    --nb_epoch 25\n",
    "    --early_stopping 5\n",
    "    \"\n",
    "fi\n",
    "run $cmd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we evaluate our fine-tuned model and impute methylation profiles using `dcpg_eval.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "#################################\r\n",
      "dcpg_eval.py ./data/c1_000000-010000.h5 --model_files ./models/cpg --out_data ./eval/data.h5 --out_report ./eval/report.tsv --nb_sample 1000\r\n",
      "#################################\r\n",
      "Using TensorFlow backend.\r\n",
      "INFO (2017-02-05 21:04:35,849): Loading model ...\r\n",
      "INFO (2017-02-05 21:04:36,671): Loading data ...\r\n",
      "INFO (2017-02-05 21:04:36,682): Predicting ...\r\n",
      "INFO (2017-02-05 21:04:36,697):  128/1000 (12.8%)\r\n",
      "INFO (2017-02-05 21:04:36,823):  256/1000 (25.6%)\r\n",
      "INFO (2017-02-05 21:04:36,943):  384/1000 (38.4%)\r\n",
      "INFO (2017-02-05 21:04:37,063):  512/1000 (51.2%)\r\n",
      "INFO (2017-02-05 21:04:37,194):  640/1000 (64.0%)\r\n",
      "INFO (2017-02-05 21:04:37,322):  768/1000 (76.8%)\r\n",
      "INFO (2017-02-05 21:04:37,432):  896/1000 (89.6%)\r\n",
      "INFO (2017-02-05 21:04:37,530): 1000/1000 (100.0%)\r\n",
      "/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\r\n",
      "  'precision', 'predicted', average, warn_for)\r\n",
      "           output       auc       acc       tpr       tnr        f1       mcc      n\r\n",
      "2  cpg/BS27_5_SER  0.614029  0.850000  0.989362  0.031250  0.918519  0.062658  220.0\r\n",
      "1  cpg/BS27_3_SER  0.574713  0.630137  0.663793  0.500000  0.740385  0.137086  146.0\r\n",
      "0  cpg/BS27_1_SER  0.520723  0.139601  0.044444  0.972222  0.084848  0.025000  351.0\r\n",
      "3  cpg/BS27_6_SER  0.437062  0.500000  0.580357  0.339286  0.607477 -0.077563  336.0\r\n",
      "4  cpg/BS27_8_SER  0.424276  0.076087  0.000000  1.000000  0.000000  0.000000  276.0\r\n",
      "INFO (2017-02-05 21:04:37,720): Done!\r\n"
     ]
    }
   ],
   "source": [
    "eval_dir=\"./eval\"\n",
    "mkdir -p $eval_dir\n",
    "\n",
    "cmd=\"dcpg_eval.py\n",
    "    $dcpg_data/*.h5\n",
    "    --model_files ./models/cpg\n",
    "    --out_data $eval_dir/data.h5\n",
    "    --out_report $eval_dir/report.tsv\n",
    "    \"\n",
    "if [[ $test_mode -eq 1 ]]; then\n",
    "    cmd=\"$cmd\n",
    "        --nb_sample 1000\n",
    "        \"\n",
    "fi\n",
    "run $cmd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
